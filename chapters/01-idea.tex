\def\code#1{\texttt{#1}}

\section{Ideation}
We are in the middle of a paradigm shift of how we interact with computers, language, and information. The current
so-called "AI Revolution" can have its origin traced back to late 2016-early 2017 when "AI" (as we refer today) was able
to synthesise new data as deepfakes, no longer limited to mere classification. As deepfake matures, the world started to
ponder: If deepfakes are possible, can we push this generative into other domains? After a brief period of silent
refinement and research came the answer: A resounding yes. GPT-1 debutted in  2018, followed by GPT-2 in 2019; finally
culminated into the start of the "AI Revolution", GPT-3, colloquially known as "ChatGPT".

The world took notice very quickly. GPT-3 and later models excelled at natural language processing (NLP), generating
responses the likes of Cleverbot could never hoped to match. But, a sword to protect is also a sword for violence, as
AI-based cheating became more and more prolific amongst student. Why bother labouring away at assignments when you
could ask to "please generate an essay on \$\{a topic\}"? An arms race have begun: Students who wanted a quick way out,
and educators who wanted to curb the rampant low-effort submissions. Pandora's Box had been opened, there was no going
back. There was only more education on how to wield AI as a tool, which got us thinking.

LLMs' strength lies in NLP, i.e., its ability to crunch through hundreds of pages of text, teasing out details, and
based on its training with sufficient guidance (i.e., prompting), could help a well-trained individual to cut down on
time needed to meaningfully parse through a document. Examples of this can be seen in the existence of numerous AI
academic research aids: The LLM with their tools will blast through a research question, finding the relevant papers,
distill them down to answer the question, and leave it for the human to judge whether the material found is suitable
for their current objective. It is this abililty to aid humans that we wanted to harness.

Key words: "well-trained individual". What about the not well-trained? We have seen in the past tools such as PhotoMath,
WolframAlpha being used to solve a problem for a student to copy down and call it done. As far as the education system
is concerned, you have proved your ability to solve a problem, but as far as your brain is concerned, you have not
learnt anything. And as digital note-taking become more or more prevalent in K-12, not just as college/university
students, we wanted to let AI empower K-12 and university students of STEM fields, in much the same way AI is
empowering academia.

We would like to propose: "\textbf{CogniMind}, a notebook note-taking app, with AI features tailored towards students".
We want to achieve this by purposefully restricting the LLM's capability into 3 stages: Priming the user with hints on
required knowledge; Socratic questioning to guide the user through; and full solution. The goal is for the user to
connect the dots themselves, rather than spoonfeeding.

Our startup will \textbf{strictly focus on STEM subjects}. The law of physics is the same regardless of countries,
whereas culture can differ wildly from one region to the next, sometimes within the same country. An LLM would need a
full-scale anthropology research project culminating into thousands upon thousands of pages of text describing in
painstaking detail every nuances; the scale of which is a state-sponsored project. As LLMs can hallucinate (this is by
nature as a token (i.e., morpheme, loosely) predictor), by focusing strictly on STEM subjects where there is a
"universal truth", we can prevent misinformation on factual subjects that can distort a student's view, especially on
sensitive topics.